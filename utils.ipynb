{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adb6af3b-4aee-4d4f-8cf0-27e962892ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17ce4d66-259f-4cd8-8e58-12dc787f600d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_file_index(data_path, inter_path):\n",
    "    \"\"\" Fix the index of training set input and test set result output. \"\"\"\n",
    "    train_lab_path = f\"{data_path}/train_label.csv\"\n",
    "    train_label = pd.read_csv(train_lab_path)\n",
    "    train_filename = train_label['filename'].tolist()\n",
    "\n",
    "    # Fix the index of test_filename\n",
    "    test_filename = sorted(os.listdir(f\"{data_path}/test/pe\"))\n",
    "    pd.DataFrame({'filename': test_filename}).to_csv(f\"{inter_path}/test_filename.txt\", header=False, index=False)\n",
    "\n",
    "    # Get the same samples labeled 7, 8, 9 both in training and test samples\n",
    "    delect_filename = train_label[train_label['family'].isin([7, 8, 9]) &\n",
    "                                  (train_label['filename'].isin(test_filename))]['filename'].tolist()\n",
    "    np.save(f\"{inter_path}/train_filename_de\", delect_filename)\n",
    "\n",
    "    # Get rid of training samples labeled 7, 8, 9 but not in the test set\n",
    "    other_filename = train_label[train_label['family'].isin([7, 8, 9]) &\n",
    "                                 (~train_label['filename'].isin(test_filename))]['filename'].tolist()\n",
    "    train_filename = list(set(train_filename) - set(other_filename))\n",
    "    train_label = train_label[train_label['filename'].isin(train_filename)]\n",
    "    train_filename = train_label['filename']\n",
    "    train_y = np.array(train_label['family'])\n",
    "    train_filename.to_csv(f\"{inter_path}/train_filename.txt\", header=False, index=False)\n",
    "    np.save(f\"{inter_path}/train_y.npy\", train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7df1ea12-f867-4e70-adc1-a5cced989ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vote_weight_results(labels_loss, vote_list, feature_list):\n",
    "    \"\"\" Weighted soft voting result ensemble. \"\"\"\n",
    "    result_ensemble = np.zeros(vote_list[0].shape, dtype=float)\n",
    "    final = np.zeros(vote_list[0].shape, dtype=float)\n",
    "    for i, res in enumerate(vote_list):\n",
    "        weight = np.array(labels_loss[feature_list[i]])\n",
    "        result_ensemble += res * weight\n",
    "    # Get the index of max probability\n",
    "    pred = np.argmax(result_ensemble, axis=1)\n",
    "    for i, v in enumerate(pred):\n",
    "        vals = np.array([res[i, v] for res in vote_list])\n",
    "        max_pos = np.argmax(vals)\n",
    "        final[i, :] = vote_list[max_pos][i, :]\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fd71e6-7e1a-4d4f-815b-c6046be37375",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vote_results(vote_list):\n",
    "    result_ensemble = np.zeros(vote_list[0].shape, dtype=float)\n",
    "    pred_list = []\n",
    "    final = np.zeros(vote_list[0].shape, dtype=float)\n",
    "    for res in vote_list:\n",
    "        result_ensemble += res\n",
    "        \n",
    "    pred = np.argmax(result_ensemble, axis=1)\n",
    "    for i, v in enumerate(pred):\n",
    "        vals = np.array([res[i, v] for res in vote_list])\n",
    "        max_pos = np.argmax(vals)\n",
    "        final[i, :] = vote_list[max_pos][i, :]    \n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3254486-97d3-4653-a896-0c4ff3aff0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_logloss(x):\n",
    "    \"\"\" Calculate the logloss of each family. \"\"\"\n",
    "    class_pred = np.array(x.iloc[:, :-1])\n",
    "    class_result = np.array(x['family'])\n",
    "    class_loss = log_loss_custom(class_result, class_pred)\n",
    "    return class_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61dc0400-8fcf-4a6d-8d40-d2babc1b1db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_type, feature_list, inter_path):\n",
    "    \"\"\" Get dataset (dict) made up by different features. \"\"\"\n",
    "\n",
    "    data_dict = {}\n",
    "    for feature in feature_list:\n",
    "        data_dict[feature] = np.load(f\"{inter_path}/feature/{data_type}_{feature}.npy\")\n",
    "\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41c3f889-69b4-4771-9abc-15ccf205c8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_loss_custom(y_true, y_pred):\n",
    "    \"\"\" Logloss that supports single category calculation. \"\"\"\n",
    "    summ = 0.0\n",
    "    for i in range(len(y_true)):\n",
    "        summ -= np.log(max(y_pred[i][y_true[i]], 1e-15))\n",
    "    return summ / len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46d164d-b927-4934-b6b4-c7bc77922ec9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
